專案階段總覽 (Project Pipeline)
我們的目標是訓練出一個能辨識 10 種商品的 YOLO 模型，並將其轉化為手機可用的 .tflite 格式。

第一階段：環境建置與 Git 版控 (Foundation)
很多新人會直接開始寫 Code，結果電腦當機程式碼全丟，或者把幾 GB 的圖片傳到 GitHub 被拒絕。我們先把地基打好。

1. 為什麼要用 Git？
Git 是我們的時光機。當你調整參數把模型改壞了，Git 可以讓你回到原本正常的版本。

2. 企業級 Git 操作步驟
Step A: 初始化專案 在你的電腦建立一個資料夾 Grocery_AI_Top10，打開終端機 (Terminal/CMD)：

Bash

git init
Step B: 設定 .gitignore (非常重要！) 這是新手最常卡關的地方。千萬不要把你的圖片集 (Dataset) 和訓練出來的大模型 (Weights) 上傳到 Git，那會把倉庫塞爆。

在資料夾內建立一個名為 .gitignore 的檔案，內容如下：

Plaintext

# 忽略數據集
datasets/
images/
labels/

# 忽略訓練出來的模型與 log
runs/
*.pt
*.tflite
__pycache__/

# 忽略虛擬環境
venv/
.env
Step C: 第一次提交

Bash

git add .
git commit -m "Initial commit: 設定專案結構與 gitignore"
第二階段：數據採集與標註 (Data Ops)
既然是 Top 10 商品 (例如：可樂、義美小泡芙、科學麵...)，我們需要「高品質」而非「多數量」的數據。

原則：Garbage In, Garbage Out (垃圾進，垃圾出)。

採集策略 (Data Collection)：

多角度： 正面、側面、拿在手上的樣子。

多環境： 貨架上、收銀台桌面上、強光下、陰影下。

數量： Top 10 商品，每個商品至少拍 50-100 張照片。

負樣本 (Negative Samples)： 拍幾張「沒有商品」的空貨架或桌面，這能降低誤判。

標註 (Labeling) - 使用 Roboflow：

上傳照片到 Roboflow。

畫框框 (Bounding Box)： 框要貼合商品邊緣，不要留太多空隙。

增強 (Augmentation)： 在 Roboflow 設定中開啟「旋轉」、「亮度調整」、「噪點」。這可以讓你原本的 500 張照片變身成 1500 張，讓模型更聰明。

輸出： 選擇 Export -> Format 選 YOLOv8 -> 下載 ZIP 或複製 Code。

第三階段：模型訓練 (Training with YOLOv8)
我們目前業界最常用 Ultralytics YOLOv8，因為它生態系最完整，轉 TFLite 最不容易報錯。

環境建議： 如果你電腦沒有強顯卡 (NVIDIA GPU)，請直接用 Google Colab。

Python 訓練腳本 (main.py)
這是我們會放在 Git 裡的核心程式碼：

Python

from ultralytics import YOLO

# 1. 載入模型
# 'yolov8n.pt' 是 nano 版本，最小最快，最適合手機端運行
model = YOLO('yolov8n.pt') 

# 2. 開始訓練 (Training)
# data: 指向你的 data.yaml 路徑
# epochs: 訓練輪數，建議先設 50-100
# imgsz: 圖片大小，手機端通常用 320 或 640
if __name__ == '__main__':
    results = model.train(
        data='path/to/your/dataset/data.yaml', 
        epochs=100, 
        imgsz=640, 
        batch=16,
        name='grocery_top10_v1' # 專案名稱
    )

    # 3. 驗證模型 (Validation)
    # 看看在沒看過的圖片上表現如何
    metrics = model.val()
    print(f"mAP50: {metrics.box.map50}") # 這是我們最在乎的指標：準確度

    # 4. 輸出模型 (Export) -> 關鍵步驟！
    # 將模型轉換為 TFLite 格式，供手機 App 使用
    success = model.export(format='tflite')
原理小貼士：

Epochs: 模型要把這些考題 (圖片) 讀幾遍。讀太少學不會 (Underfitting)，讀太多會死記硬背 (Overfitting)。

mAP (mean Average Precision): 我們看成績單不看 Accuracy，看 mAP。如果 mAP50 超過 0.8，表示這模型在實際場景很能打。

第四階段：幫你解開卡關的步驟 (Troubleshooting)
在開發過程中，你一定會遇到以下三個「坑」，我先幫你預判了：

卡關 1：訓練出來什麼都認不到 (信心度 0)

原因： data.yaml 路徑設錯，或者標註檔 (txt) 沒跟圖片對上。

解法： 檢查 Roboflow 下載下來的資料夾結構。確認 images 和 labels 資料夾是否配對。

卡關 2：模型把「我的手」認成「熱狗」 (誤判)

原因： 背景太單純，模型以為長條狀肉色物體就是熱狗。

解法： 加入「負樣本」(Negative Samples)，拍一些只有手、沒有商品的照片放進去訓練，但不畫任何框框。告訴模型：「這是背景，不要理它」。

卡關 3：手機上跑起來很慢

原因： 圖片尺寸 (imgsz) 太大或模型太肥。

解法：

確保使用 yolov8n (nano 版)。

訓練時 imgsz 設為 320 或 416 (犧牲一點點準確度換取極致速度)。

匯出 TFLite 時使用 int8 量化 (Quantization)，這會讓模型體積縮小 4 倍。

Python

# int8 量化輸出範例
model.export(format='tflite', int8=True, data='path/to/data.yaml')
你的下一步 (Action Item)
作為 AI 部門的工程師，我建議你現在做這個操作：

「先不要急著寫 Code，先去 Roboflow 建立專案，並用手機拍下這 10 樣商品各 20 張照片 (包含不同角度)，完成標註並輸出 data.yaml。」

需要我教你怎麼看 Roboflow 輸出的 data.yaml 格式，確保它能被 YOLO 讀取嗎？











------------------







git commit -m "Initial commit: 設定專案結構與 gitignore"


直接回答你：絕對不會！之前的檔案不但不會不見，反而會被「永久保存」起來。

這就是為什麼我們寫程式一定要用 Git，而不是單純用「複製貼上備份」。讓我們用最直觀的方式來理解：

1. 傳統存檔 vs. Git 提交
傳統存檔 (像 Word/Excel): 當你按下儲存，新內容會覆蓋舊內容。

結局：你就再也找不回上一版的文字了。

Git 提交 (Commit): 當你執行 git commit，Git 不會覆蓋舊的，而是拍一張新的「快照」(Snapshot) 並疊加上去。

結局：你會有第一版、第二版、第三版...全部都留著。

你可以把 Git 想像成RPG 遊戲的存檔機制：

Commit 1: 等級 1，剛出新手村 (你剛剛做的 Initial commit)。

Commit 2: 等級 10，學會火球術 (下次你寫好 train_yolo.py 再次 commit)。

Commit 3: 等級 50，打敗大魔王。

如果你在等級 50 的時候把裝備賣光了 (把程式碼改爛了)，你可以隨時讀取進度回到等級 10，甚至回到等級 1。之前的存檔永遠都在。

2. 如何證明之前的還在？(指令驗證)
你可以現在就在終端機輸入這行指令，它是你的「時光機日誌」：

Bash
git log
你現在應該會看到類似這樣的畫面：








------------

12/14:開始使用Roboflow標註top10影像，然後切記，data不要有中文名，train會error


12/15:top_10 tag完成並翻轉與噪音增強。





--------------------












第一部分：為什麼這樣寫？（原理與邏輯）
你的原始程式碼已經掌握了核心，以下是針對「雜貨店場景」的深度解析：

model = YOLO('yolov11n.pt')

原理： 這是 遷移學習 (Transfer Learning)。你不需要從頭教電腦「什麼是線條、什麼是圓形」，而是使用已經看過千萬張圖片的 YOLOv11n 模型，讓它將既有的視覺能力「遷移」到你的餅乾、飲料上。

為何選 Nano (n)？ 手機算力有限，Nano 版本參數最少，推論速度最快，最不容易造成手機發燙或 App 卡頓。

imgsz=640

權衡： 雜貨店商品通常字體小、包裝像。設 640 是標準；如果商品很小（如口香糖），可能需要設 imgsz=1280（但手機會跑不動）。640 是目前的甜蜜點。

format='tflite'

關鍵： PyTorch 模型 (.pt) 不能直接在一般 Android/iOS 專案中高效運行。TFLite 是 Google 專為行動裝置優化的格式。甚至可以進一步轉為 int8 量化版本，讓體積縮小 4 倍。

第二部分：強化版 main.py
研發部門的代碼需要更強的結構性與容錯率。我幫你重寫了一個版本，增加了路徑檢查、錯誤處理，以及更清晰的參數設定。

Python

import os
import sys
from ultralytics import YOLO

def train_grocery_model():
    """
    雜貨店商品辨識模型訓練主程序
    """
    # --- 1. 專案設定 (Configuration) ---
    PROJECT_NAME = 'grocery_recognition_v1'
    # 指向你的 yaml 檔案 (請確保路徑正確，建議使用絕對路徑或相對路徑)
    DATA_YAML_PATH = 'datasets/grocery_data.yaml' 
    MODEL_TYPE = 'yolo11n.pt'  # 使用 Nano 版本
    EPOCHS = 100
    IMG_SIZE = 640
    BATCH_SIZE = 16  # 若顯卡記憶體不足(OOM)，請改為 8 或 4

    # 檢查資料設定檔是否存在，避免跑很久才報錯
    if not os.path.exists(DATA_YAML_PATH):
        print(f"❌ 錯誤：找不到資料設定檔：{DATA_YAML_PATH}")
        print("💡 請確認 'datasets' 資料夾內是否有該檔案。")
        sys.exit(1)

    print(f"🚀 開始載入模型：{MODEL_TYPE}...")
    
    # --- 2. 載入模型 ---
    try:
        model = YOLO(MODEL_TYPE)
    except Exception as e:
        print(f"❌ 模型載入失敗：{e}")
        return

    # --- 3. 開始訓練 (Training) ---
    print(f"🏋️ 開始訓練... (Epochs: {EPOCHS})")
    try:
        results = model.train(
            data=DATA_YAML_PATH,
            epochs=EPOCHS,
            imgsz=IMG_SIZE,
            batch=BATCH_SIZE,
            project='runs/train', # 訓練結果存檔根目錄
            name=PROJECT_NAME,    # 本次實驗名稱
            patience=20,          # 早停機制：如果20輪沒進步就提早結束，節省時間
            exist_ok=True,        # 允許覆蓋同名實驗夾
            device=0              # 使用第一張 GPU，若無 GPU 則刪除此行或改為 'cpu'
        )
    except Exception as e:
        print(f"❌ 訓練過程中斷：{e}")
        print("💡 常見原因：路徑錯誤、顯卡記憶體不足、YAML 格式錯誤。")
        return

    # --- 4. 驗證模型 (Validation) ---
    print("🔍 正在驗證模型表現...")
    metrics = model.val()
    print(f"✅ mAP50 (準確度指標): {metrics.box.map50:.4f}")

    # --- 5. 輸出模型 (Export to TFLite) ---
    print("📦 正在轉換模型為 TFLite 格式 (供手機使用)...")
    try:
        # int8 量化能讓模型更小、在手機跑更快，但精度會微降
        # 如果發現不準，可以拿掉 int8=True
        success = model.export(format='tflite', int8=True) 
        print(f"🎉 導出成功！檔案位於 runs/train/{PROJECT_NAME}/weights/ 內")
    except Exception as e:
        print(f"⚠️ 導出 TFLite 失敗：{e}")
        print("💡 請確認是否已安裝 tensorflow： pip install tensorflow")

if __name__ == '__main__':
    # 確保程式碼只在直接執行時運作，避免多進程錯誤 (Windows 下尤為重要)
    train_grocery_model()
第三部分：解開「卡關」的步驟 (Troubleshooting)
在研發階段，最容易卡住的地方通常不是程式碼，而是環境與資料格式。

1. 資料集結構 (最常錯的地方)
YOLO 對資料夾結構非常嚴格。你的專案目錄應該長這樣：

Plaintext

Grocery_Project/
├── main.py
├── yolov11n.pt
├── .gitignore
└── datasets/
    └── grocery_data.yaml  <-- 設定檔
    └── images/
        ├── train/ (放訓練圖 80%)
        └── val/   (放驗證圖 20%)
    └── labels/
        ├── train/ (放對應的 .txt 標註檔)
        └── val/   (放對應的 .txt 標註檔)
grocery_data.yaml 的內容範例：

YAML

path: ../datasets  # 根目錄路徑
train: images/train
val: images/val

nc: 3  # 類別數量 (例如：可樂, 洋芋片, 泡麵)
names: ['coke', 'chips', 'noodles'] # 類別名稱
2. 環境依賴
要成功導出 TFLite，你需要額外的套件。請在終端機執行：

Bash

pip install ultralytics
pip install tensorflow  # 導出 TFLite 必須
pip install onnx        # 推薦安裝，作為中間格式
第四部分：R&D 的 Git 管理策略
研發部門必須做版本控制，但 AI 專案跟一般軟體開發不同，不要把幾 GB 的圖片或模型上傳到 Git！

1. 建立 .gitignore 檔案
在專案根目錄建立一個 .gitignore 檔案，貼上以下內容：

Plaintext

# --- Python 一般忽略 ---
__pycache__/
*.py[cod]
*.venv
.env

# --- YOLO/AI 專用忽略 (重要！) ---
# 忽略資料集 (通常很大，另外備份在 NAS 或雲端)
datasets/

# 忽略訓練過程產出的權重檔與日誌
runs/
*.pt
*.tflite
*.onnx

# 忽略 IDE 設定
.vscode/
.idea/
2. 什麼要 Commit？
main.py (原始碼)

requirements.txt (環境清單：pip freeze > requirements.txt)

grocery_data.yaml (資料結構設定，但不包含圖片本身)

README.md (說明文件：如何安裝、如何訓練)

給研發部門的下一步建議
目前的程式碼已經可以跑通流程。為了讓這個「雜貨店辨識系統」真正落地到手機 App，你需要做下一步驗證：

您希望我針對以下哪一點進行深入說明？

資料標註技巧： 如何快速標註幾百個商品？(介紹 LabelImg 或 CVAT)。

App 整合端： 拿到 .tflite 檔案後，Android/iOS 工程師該怎麼呼叫它？

困難案例處理： 雜貨店會有「反光」、「商品被遮擋」的問題，如何在訓練時透過 Data Augmentation (資料增強) 來解決？







------------






.gitignore要放在根目錄





# -n 的意思是 dry-run (演習)，它會告訴你它「打算」加入什麼，但不會真的加入
git add 03_AI_Lab -n



---------------







您好！這是 Git 的一個非常重要的警告，它揭示了您專案結構中的一個 重大問題！

這個警告 warning: adding embedded git repository: 03_AI_Lab 告訴我們：

您的 03_AI_Lab 資料夾本身就是一個獨立的 Git 倉庫。

這意味著：

您在專案根目錄 D:\product_recognition\ 執行了 git init (外部倉庫)。

您在 D:\product_recognition\03_AI_Lab\ 資料夾內也執行了一次 git init (內部倉庫)。

Git 現在看到一個倉庫裡面包著另一個倉庫，這會導致未來協作和版本控制上非常大的困擾。

🚨 緊急處理步驟 (二選一)
在這種情況下，您必須決定 03_AI_Lab 內的程式碼應該如何被管理。

選項 A (推薦：將所有程式碼納入主倉庫)
這是最常見且最簡單的 R&D 專案管理方式，讓所有程式碼都在同一個 Git 歷史中。

操作：刪除內部 Git 記錄

進入內部資料夾：

Bash

cd 03_AI_Lab
刪除 .git 資料夾： 這個資料夾是讓它成為 Git 倉庫的關鍵。刪除它，它就會變成一個普通的資料夾。

Bash

# Windows 指令：
rmdir /s /q .git

# 或 Mac/Linux 指令 (如果您在 WSL 或 Git Bash)：
# rm -rf .git
返回根目錄：

Bash

cd ..
再次 Add (確認)：

Bash




##不能有過多git 倉庫。


🧭 步驟一：如何進入 WSL1. 啟動 WSL最簡單的方法： 在 Windows 的搜尋欄 (或按下 Win + S) 輸入 Ubuntu (或您安裝的 Linux 發行版名稱，例如 Debian、Kali 等)，然後點擊開啟。專業的方法： 開啟 Windows 的 PowerShell 或 命令提示字元 (CMD)，然後輸入 wsl 並按下 Enter。2. 初始位置當您啟動 WSL 時，通常會直接進入您的家目錄 (即 ~ 或 /home/kunzh)。🎯 步驟二：導航到指定目錄 (進入 product_recognition_linux)要從您的家目錄 (~) 移動到 ~/product_recognition_linux，您需要使用 cd (Change Directory) 指令。✅ 程式碼：進入目錄Bashcd product_recognition_linux
說明： cd 後面直接接上您要進入的資料夾名稱。小技巧： 您可以輸入 cd pro 然後按下鍵盤上的 Tab 鍵。Linux 會自動為您完成名稱 (例如變成 product_recognition_linux/)，這可以避免打錯字。確認成功： 當您成功進入後，命令提示字元會變更為：kunzh@USER0408:~/product_recognition_linux$📁 步驟三：檢查目錄中的檔案一旦您進入了正確的目錄，您需要使用 ls (List) 指令來查看其中包含的檔案和子目錄。✅ 程式碼：檢查檔案清單1. 基本清單 (推薦)Bashls -l
功能： 列出目錄中的所有檔案和資料夾，並顯示詳細資訊。-l 參數： 表示 "long listing format" (長格式清單)，它會顯示檔案的權限、擁有者、大小和修改日期。這對於檢查專案檔案非常有用。2. 顯示隱藏檔案Bashls -la
功能： 除了長格式清單外，還會顯示隱藏檔案。-a 參數： 表示 "all"，在 Linux 中，檔名開頭是 . 的檔案或資料夾是隱藏的 (例如 .git、.gitignore)。指令目的範例輸出片段 (您專案中可能有的)cd ..返回上一級目錄kunzh@USER0408:~/$pwd顯示目前所在的完整路徑/home/kunzh/product_recognition_linuxls -l查看檔案詳細資訊-rw-r--r-- 1 kunzh kunzh 1024 Dec 14 20:00 requirements.txt🛠️ 專案常見檢查指令在 ~/product_recognition_linux$ 目錄中，您可能會想執行以下操作：檢查專案依賴 (dependencies) 檔案的內容：Bashcat requirements.txt
cat 指令會將檔案的內容直接輸出到螢幕上。確認環境中是否已啟動虛擬環境 (如果之前未刪除)：Bashsource venv/bin/activate
如果 venv 存在，執行後您的命令提示字元會變成 (venv) kunzh@USER0408:~/product_recognition_linux$。這些基本的 cd 和 ls 指令是您在 WSL 中高效工作的基礎！明天見！12/16




12/17 TEST
這完全符合 YOLO（以及所有深度學習模型） 的特性。這種現象我們稱為「領域偏移（Domain Shift）」或是「資料分佈不一致」。

當你只是更換了擺設方式（例如：商品疊放、側放、光線改變、背景從木頭換成塑膠），對於模型來說，這些像素的組合與它在訓練時看到的完全不同，因此準確度會大幅下降。

要解開這個「換了擺設就不認得」的卡關點，你需要從以下三個核心原理動手：

一、 解決原理：提高模型的「泛化能力 (Generalization)」
模型目前的狀態是「死背」，而不是「理解」。

資料多樣性 (Data Diversity)： 模型只看過「排隊站好」的商品，沒看過「躺下」或「被遮擋」的商品。

資料增強 (Data Augmentation)： 在訓練時，讓模型自動把圖片旋轉、縮放、改變亮度，模擬不同的環境。

模型複雜度 (Epochs)： 你之前的訓練只跑了 1 個 Epoch，模型根本還沒學會特徵，它現在只是在「隨機亂猜」。

二、 實作修正步驟
為了讓 YOLO 變聰明，請針對你的 03_AI_Lab/train_grocery_model.py 進行以下兩項重大調整：

1. 增加訓練輪數 (Epochs)
這最關鍵。 1 輪絕對不夠，至少要讓模型看 100 次以上的資料。

2. 加入資料增強參數
在 model.train() 裡面加入一些控制項，強制模型學習不同角度的商品。

請修改 train_grocery_model.py 中的 model.train 區塊：

Python

# --- 3. 開始訓練 (Training) ---
print(f"🏋️ 開始訓練... (Epochs: 100)")
try:
    results = model.train(
        data=DATA_YAML_PATH,
        epochs=100,            # <--- 修正點 1: 從 1 改為 100
        imgsz=IMG_SIZE,
        batch=BATCH_SIZE,
        project='03_AI_Lab/runs/train',
        name=PROJECT_NAME,
        patience=20,           
        exist_ok=True,
        device=0,
        # --- 修正點 2: 加入資料增強參數 ---
        degrees=15.0,         # 隨機旋轉正負 15 度 (應對擺設歪掉)
        translate=0.1,        # 隨機平移 (應對擺放位置不同)
        scale=0.5,            # 隨機縮放 (應對相機遠近)
        flipud=0.5,           # 50% 機率上下翻轉 (如果商品會倒過來放)
        fliplr=0.5,           # 50% 機率左右翻轉
        mosaic=1.0,           # 強大的馬賽克增強，把四張圖拼在一起（對小商品很有用）
    )
三、 步驟解鎖流程
如果你發現「換擺設就認不得」，請按照這個順序操作：

收集更多樣的圖片：

拍一些商品倒下的、側面的、疊在一起的圖片。

把這些圖片標註好，放進 yolo11_data/train 裡面。

執行長時間訓練：

執行上面修改後的 train_grocery_model.py (跑 100 輪)。

視覺化測試：

訓練完後，再跑一次 predict_test.py。這時候你應該會發現，即便擺法不同，信心分數（Confidence）也會顯著提升。

四、 關於版控的小提醒
因為你接下來要進行大工程（增加圖片、跑 100 輪訓練），這會產生大量的結果檔案：

千萬不要 Push runs/ 資料夾：訓練 100 輪後，runs/ 會變得很巨大。

只 Push 代碼：確認你的 .gitignore 已經寫好 03_AI_Lab/runs/。

接下來您可以做什麼？ 你想先修改訓練程式碼並開始跑 100 輪訓練，還是需要我幫你寫一個腳本來檢查你的資料集圖片是否夠多樣化？