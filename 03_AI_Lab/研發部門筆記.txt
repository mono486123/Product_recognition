專案階段總覽 (Project Pipeline)
我們的目標是訓練出一個能辨識 10 種商品的 YOLO 模型，並將其轉化為手機可用的 .tflite 格式。

第一階段：環境建置與 Git 版控 (Foundation)
很多新人會直接開始寫 Code，結果電腦當機程式碼全丟，或者把幾 GB 的圖片傳到 GitHub 被拒絕。我們先把地基打好。

1. 為什麼要用 Git？
Git 是我們的時光機。當你調整參數把模型改壞了，Git 可以讓你回到原本正常的版本。

2. 企業級 Git 操作步驟
Step A: 初始化專案 在你的電腦建立一個資料夾 Grocery_AI_Top10，打開終端機 (Terminal/CMD)：

Bash

git init
Step B: 設定 .gitignore (非常重要！) 這是新手最常卡關的地方。千萬不要把你的圖片集 (Dataset) 和訓練出來的大模型 (Weights) 上傳到 Git，那會把倉庫塞爆。

在資料夾內建立一個名為 .gitignore 的檔案，內容如下：

Plaintext

# 忽略數據集
datasets/
images/
labels/

# 忽略訓練出來的模型與 log
runs/
*.pt
*.tflite
__pycache__/

# 忽略虛擬環境
venv/
.env
Step C: 第一次提交

Bash

git add .
git commit -m "Initial commit: 設定專案結構與 gitignore"
第二階段：數據採集與標註 (Data Ops)
既然是 Top 10 商品 (例如：可樂、義美小泡芙、科學麵...)，我們需要「高品質」而非「多數量」的數據。

原則：Garbage In, Garbage Out (垃圾進，垃圾出)。

採集策略 (Data Collection)：

多角度： 正面、側面、拿在手上的樣子。

多環境： 貨架上、收銀台桌面上、強光下、陰影下。

數量： Top 10 商品，每個商品至少拍 50-100 張照片。

負樣本 (Negative Samples)： 拍幾張「沒有商品」的空貨架或桌面，這能降低誤判。

標註 (Labeling) - 使用 Roboflow：

上傳照片到 Roboflow。

畫框框 (Bounding Box)： 框要貼合商品邊緣，不要留太多空隙。

增強 (Augmentation)： 在 Roboflow 設定中開啟「旋轉」、「亮度調整」、「噪點」。這可以讓你原本的 500 張照片變身成 1500 張，讓模型更聰明。

輸出： 選擇 Export -> Format 選 YOLOv8 -> 下載 ZIP 或複製 Code。

第三階段：模型訓練 (Training with YOLOv8)
我們目前業界最常用 Ultralytics YOLOv8，因為它生態系最完整，轉 TFLite 最不容易報錯。

環境建議： 如果你電腦沒有強顯卡 (NVIDIA GPU)，請直接用 Google Colab。

Python 訓練腳本 (main.py)
這是我們會放在 Git 裡的核心程式碼：

Python

from ultralytics import YOLO

# 1. 載入模型
# 'yolov8n.pt' 是 nano 版本，最小最快，最適合手機端運行
model = YOLO('yolov8n.pt') 

# 2. 開始訓練 (Training)
# data: 指向你的 data.yaml 路徑
# epochs: 訓練輪數，建議先設 50-100
# imgsz: 圖片大小，手機端通常用 320 或 640
if __name__ == '__main__':
    results = model.train(
        data='path/to/your/dataset/data.yaml', 
        epochs=100, 
        imgsz=640, 
        batch=16,
        name='grocery_top10_v1' # 專案名稱
    )

    # 3. 驗證模型 (Validation)
    # 看看在沒看過的圖片上表現如何
    metrics = model.val()
    print(f"mAP50: {metrics.box.map50}") # 這是我們最在乎的指標：準確度

    # 4. 輸出模型 (Export) -> 關鍵步驟！
    # 將模型轉換為 TFLite 格式，供手機 App 使用
    success = model.export(format='tflite')
原理小貼士：

Epochs: 模型要把這些考題 (圖片) 讀幾遍。讀太少學不會 (Underfitting)，讀太多會死記硬背 (Overfitting)。

mAP (mean Average Precision): 我們看成績單不看 Accuracy，看 mAP。如果 mAP50 超過 0.8，表示這模型在實際場景很能打。

第四階段：幫你解開卡關的步驟 (Troubleshooting)
在開發過程中，你一定會遇到以下三個「坑」，我先幫你預判了：

卡關 1：訓練出來什麼都認不到 (信心度 0)

原因： data.yaml 路徑設錯，或者標註檔 (txt) 沒跟圖片對上。

解法： 檢查 Roboflow 下載下來的資料夾結構。確認 images 和 labels 資料夾是否配對。

卡關 2：模型把「我的手」認成「熱狗」 (誤判)

原因： 背景太單純，模型以為長條狀肉色物體就是熱狗。

解法： 加入「負樣本」(Negative Samples)，拍一些只有手、沒有商品的照片放進去訓練，但不畫任何框框。告訴模型：「這是背景，不要理它」。

卡關 3：手機上跑起來很慢

原因： 圖片尺寸 (imgsz) 太大或模型太肥。

解法：

確保使用 yolov8n (nano 版)。

訓練時 imgsz 設為 320 或 416 (犧牲一點點準確度換取極致速度)。

匯出 TFLite 時使用 int8 量化 (Quantization)，這會讓模型體積縮小 4 倍。

Python

# int8 量化輸出範例
model.export(format='tflite', int8=True, data='path/to/data.yaml')
你的下一步 (Action Item)
作為 AI 部門的工程師，我建議你現在做這個操作：

「先不要急著寫 Code，先去 Roboflow 建立專案，並用手機拍下這 10 樣商品各 20 張照片 (包含不同角度)，完成標註並輸出 data.yaml。」

需要我教你怎麼看 Roboflow 輸出的 data.yaml 格式，確保它能被 YOLO 讀取嗎？











------------------







git commit -m "Initial commit: 設定專案結構與 gitignore"


直接回答你：絕對不會！之前的檔案不但不會不見，反而會被「永久保存」起來。

這就是為什麼我們寫程式一定要用 Git，而不是單純用「複製貼上備份」。讓我們用最直觀的方式來理解：

1. 傳統存檔 vs. Git 提交
傳統存檔 (像 Word/Excel): 當你按下儲存，新內容會覆蓋舊內容。

結局：你就再也找不回上一版的文字了。

Git 提交 (Commit): 當你執行 git commit，Git 不會覆蓋舊的，而是拍一張新的「快照」(Snapshot) 並疊加上去。

結局：你會有第一版、第二版、第三版...全部都留著。

你可以把 Git 想像成RPG 遊戲的存檔機制：

Commit 1: 等級 1，剛出新手村 (你剛剛做的 Initial commit)。

Commit 2: 等級 10，學會火球術 (下次你寫好 train_yolo.py 再次 commit)。

Commit 3: 等級 50，打敗大魔王。

如果你在等級 50 的時候把裝備賣光了 (把程式碼改爛了)，你可以隨時讀取進度回到等級 10，甚至回到等級 1。之前的存檔永遠都在。

2. 如何證明之前的還在？(指令驗證)
你可以現在就在終端機輸入這行指令，它是你的「時光機日誌」：

Bash
git log
你現在應該會看到類似這樣的畫面：








------------

12/14:開始使用Roboflow標註top10影像，然後切記，data不要有中文名，train會error


12/15:top_10 tag完成並翻轉與噪音增強。





--------------------












第一部分：為什麼這樣寫？（原理與邏輯）
你的原始程式碼已經掌握了核心，以下是針對「雜貨店場景」的深度解析：

model = YOLO('yolov11n.pt')

原理： 這是 遷移學習 (Transfer Learning)。你不需要從頭教電腦「什麼是線條、什麼是圓形」，而是使用已經看過千萬張圖片的 YOLOv11n 模型，讓它將既有的視覺能力「遷移」到你的餅乾、飲料上。

為何選 Nano (n)？ 手機算力有限，Nano 版本參數最少，推論速度最快，最不容易造成手機發燙或 App 卡頓。

imgsz=640

權衡： 雜貨店商品通常字體小、包裝像。設 640 是標準；如果商品很小（如口香糖），可能需要設 imgsz=1280（但手機會跑不動）。640 是目前的甜蜜點。

format='tflite'

關鍵： PyTorch 模型 (.pt) 不能直接在一般 Android/iOS 專案中高效運行。TFLite 是 Google 專為行動裝置優化的格式。甚至可以進一步轉為 int8 量化版本，讓體積縮小 4 倍。

第二部分：強化版 main.py
研發部門的代碼需要更強的結構性與容錯率。我幫你重寫了一個版本，增加了路徑檢查、錯誤處理，以及更清晰的參數設定。

Python

import os
import sys
from ultralytics import YOLO

def train_grocery_model():
    """
    雜貨店商品辨識模型訓練主程序
    """
    # --- 1. 專案設定 (Configuration) ---
    PROJECT_NAME = 'grocery_recognition_v1'
    # 指向你的 yaml 檔案 (請確保路徑正確，建議使用絕對路徑或相對路徑)
    DATA_YAML_PATH = 'datasets/grocery_data.yaml' 
    MODEL_TYPE = 'yolo11n.pt'  # 使用 Nano 版本
    EPOCHS = 100
    IMG_SIZE = 640
    BATCH_SIZE = 16  # 若顯卡記憶體不足(OOM)，請改為 8 或 4

    # 檢查資料設定檔是否存在，避免跑很久才報錯
    if not os.path.exists(DATA_YAML_PATH):
        print(f"❌ 錯誤：找不到資料設定檔：{DATA_YAML_PATH}")
        print("💡 請確認 'datasets' 資料夾內是否有該檔案。")
        sys.exit(1)

    print(f"🚀 開始載入模型：{MODEL_TYPE}...")
    
    # --- 2. 載入模型 ---
    try:
        model = YOLO(MODEL_TYPE)
    except Exception as e:
        print(f"❌ 模型載入失敗：{e}")
        return

    # --- 3. 開始訓練 (Training) ---
    print(f"🏋️ 開始訓練... (Epochs: {EPOCHS})")
    try:
        results = model.train(
            data=DATA_YAML_PATH,
            epochs=EPOCHS,
            imgsz=IMG_SIZE,
            batch=BATCH_SIZE,
            project='runs/train', # 訓練結果存檔根目錄
            name=PROJECT_NAME,    # 本次實驗名稱
            patience=20,          # 早停機制：如果20輪沒進步就提早結束，節省時間
            exist_ok=True,        # 允許覆蓋同名實驗夾
            device=0              # 使用第一張 GPU，若無 GPU 則刪除此行或改為 'cpu'
        )
    except Exception as e:
        print(f"❌ 訓練過程中斷：{e}")
        print("💡 常見原因：路徑錯誤、顯卡記憶體不足、YAML 格式錯誤。")
        return

    # --- 4. 驗證模型 (Validation) ---
    print("🔍 正在驗證模型表現...")
    metrics = model.val()
    print(f"✅ mAP50 (準確度指標): {metrics.box.map50:.4f}")

    # --- 5. 輸出模型 (Export to TFLite) ---
    print("📦 正在轉換模型為 TFLite 格式 (供手機使用)...")
    try:
        # int8 量化能讓模型更小、在手機跑更快，但精度會微降
        # 如果發現不準，可以拿掉 int8=True
        success = model.export(format='tflite', int8=True) 
        print(f"🎉 導出成功！檔案位於 runs/train/{PROJECT_NAME}/weights/ 內")
    except Exception as e:
        print(f"⚠️ 導出 TFLite 失敗：{e}")
        print("💡 請確認是否已安裝 tensorflow： pip install tensorflow")

if __name__ == '__main__':
    # 確保程式碼只在直接執行時運作，避免多進程錯誤 (Windows 下尤為重要)
    train_grocery_model()
第三部分：解開「卡關」的步驟 (Troubleshooting)
在研發階段，最容易卡住的地方通常不是程式碼，而是環境與資料格式。

1. 資料集結構 (最常錯的地方)
YOLO 對資料夾結構非常嚴格。你的專案目錄應該長這樣：

Plaintext

Grocery_Project/
├── main.py
├── yolov11n.pt
├── .gitignore
└── datasets/
    └── grocery_data.yaml  <-- 設定檔
    └── images/
        ├── train/ (放訓練圖 80%)
        └── val/   (放驗證圖 20%)
    └── labels/
        ├── train/ (放對應的 .txt 標註檔)
        └── val/   (放對應的 .txt 標註檔)
grocery_data.yaml 的內容範例：

YAML

path: ../datasets  # 根目錄路徑
train: images/train
val: images/val

nc: 3  # 類別數量 (例如：可樂, 洋芋片, 泡麵)
names: ['coke', 'chips', 'noodles'] # 類別名稱
2. 環境依賴
要成功導出 TFLite，你需要額外的套件。請在終端機執行：

Bash

pip install ultralytics
pip install tensorflow  # 導出 TFLite 必須
pip install onnx        # 推薦安裝，作為中間格式
第四部分：R&D 的 Git 管理策略
研發部門必須做版本控制，但 AI 專案跟一般軟體開發不同，不要把幾 GB 的圖片或模型上傳到 Git！

1. 建立 .gitignore 檔案
在專案根目錄建立一個 .gitignore 檔案，貼上以下內容：

Plaintext

# --- Python 一般忽略 ---
__pycache__/
*.py[cod]
*.venv
.env

# --- YOLO/AI 專用忽略 (重要！) ---
# 忽略資料集 (通常很大，另外備份在 NAS 或雲端)
datasets/

# 忽略訓練過程產出的權重檔與日誌
runs/
*.pt
*.tflite
*.onnx

# 忽略 IDE 設定
.vscode/
.idea/
2. 什麼要 Commit？
main.py (原始碼)

requirements.txt (環境清單：pip freeze > requirements.txt)

grocery_data.yaml (資料結構設定，但不包含圖片本身)

README.md (說明文件：如何安裝、如何訓練)

給研發部門的下一步建議
目前的程式碼已經可以跑通流程。為了讓這個「雜貨店辨識系統」真正落地到手機 App，你需要做下一步驗證：

您希望我針對以下哪一點進行深入說明？

資料標註技巧： 如何快速標註幾百個商品？(介紹 LabelImg 或 CVAT)。

App 整合端： 拿到 .tflite 檔案後，Android/iOS 工程師該怎麼呼叫它？

困難案例處理： 雜貨店會有「反光」、「商品被遮擋」的問題，如何在訓練時透過 Data Augmentation (資料增強) 來解決？







------------






.gitignore要放在根目錄





# -n 的意思是 dry-run (演習)，它會告訴你它「打算」加入什麼，但不會真的加入
git add 03_AI_Lab -n



---------------




