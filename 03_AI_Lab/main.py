import os
import cv2
import numpy as np
import shutil
import yaml
from ultralytics import YOLO
from pathlib import Path

# ==========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå¢å¼·ç‰ˆè³‡æ–™æ“´å…… (å«ç¿»è½‰ã€å…‰å½±)
# ==========================================

def augment_dataset(data_root):
    train_img_dir = os.path.join(data_root, "train", "images")
    train_lab_dir = os.path.join(data_root, "train", "labels")
    
    if not os.path.exists(train_img_dir):
        print(f"âš ï¸ æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{train_img_dir}")
        return

    print("ğŸ”„ å•Ÿå‹•è³‡æ–™æ“´å……ï¼šè™•ç†æ°´å¹³ç¿»è½‰èˆ‡å…‰å½±è®Šå¹»...")
    
    # åƒ…è™•ç†åŸå§‹æª”æ¡ˆï¼Œä¸è™•ç†å·²ç¶“å¸¶æœ‰å¾Œç¶´çš„æ“´å……æª”
    img_list = [f for f in os.listdir(train_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png')) 
                and not any(x in f for x in ['_flip', '_bright', '_dark'])]
    
    for img_name in img_list:
        base_name = os.path.splitext(img_name)[0]
        img_path = os.path.join(train_img_dir, img_name)
        lab_path = os.path.join(train_lab_dir, base_name + ".txt")
        
        img = cv2.imread(img_path)
        if img is None: continue

        # æº–å‚™è¦ç”¢ç”Ÿçš„è®Šé«”æ¸…å–®ï¼š(å¾Œç¶´, å½±åƒè™•ç†å‡½å¼)
        variants = [
            ("_flip", lambda x: cv2.flip(x, 1)),
            ("_bright", lambda x: cv2.convertScaleAbs(x, alpha=1.2, beta=30)),
            ("_dark", lambda x: cv2.convertScaleAbs(x, alpha=0.8, beta=-30))
        ]

        for suffix, func in variants:
            aug_name = f"{base_name}{suffix}.jpg"
            aug_img_path = os.path.join(train_img_dir, aug_name)
            aug_lab_path = os.path.join(train_lab_dir, f"{base_name}{suffix}.txt")

            if not os.path.exists(aug_img_path):
                # è™•ç†ä¸¦å„²å­˜åœ–ç‰‡
                new_img = func(img)
                cv2.imwrite(aug_img_path, new_img)
                
                # è™•ç†æ¨™ç±¤
                if os.path.exists(lab_path):
                    with open(lab_path, 'r') as f:
                        lines = f.readlines()
                    
                    new_labels = []
                    for line in lines:
                        parts = line.split()
                        if len(parts) == 5:
                            cls, x, y, w, h = map(float, parts)
                            # å¦‚æœæ˜¯ç¿»è½‰ï¼Œéœ€è¦é‡æ–°è¨ˆç®— x åº§æ¨™
                            if suffix == "_flip":
                                x = 1.0 - x
                            new_labels.append(f"{int(cls)} {x:.6f} {y:.6f} {w:.6f} {h:.6f}")
                    
                    with open(aug_lab_path, 'w') as f:
                        f.write("\n".join(new_labels))

    print(f"âœ… è³‡æ–™æ“´å……å·²å®Œæˆï¼ç›®å‰è¨“ç·´é›†è¦æ¨¡ï¼š{len(os.listdir(train_img_dir))} å¼µåœ–ç‰‡")

# ==========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šè¨“ç·´æµç¨‹èˆ‡ä¸€è‡´æ€§æª¢æŸ¥
# ==========================================

def train_grocery_model():
    DATA_ROOT = r"D:\product_recognition\03_AI_Lab\yolo11_data\drink"
    DATA_YAML = os.path.join(DATA_ROOT, "data.yaml")
    MODEL_WEIGHTS = "yolo11m.pt" 

    # 0. æª¢æŸ¥ YAML å…§å®¹ (ç¢ºä¿ Index 23 çš„ Small_Water æœ‰è£œé€²å»)
    with open(DATA_YAML, 'r') as f:
        config = yaml.safe_load(f)
    if len(config['names']) != config['nc']:
        print(f"âŒ è­¦å‘Šï¼šnc={config['nc']} ä½† names åªæœ‰ {len(config['names'])} å€‹ï¼è«‹ä¿®æ­£ data.yaml")
        return

    # 1. åŸ·è¡Œæ‰‹å‹•æ“´å……
    augment_dataset(DATA_ROOT)

    # 2. åˆå§‹åŒ– YOLO æ¨¡å‹
    print(f"ğŸš€ è¼‰å…¥æ¨¡å‹ï¼š{MODEL_WEIGHTS}...")
    model = YOLO(MODEL_WEIGHTS)

    # 3. é–‹å§‹è¨“ç·´ (é‡å°å°æ¨£æœ¬èˆ‡æ··æ·†é¡åˆ¥å„ªåŒ–)
    print("ğŸ‹ï¸ é–‹å§‹é‡å°æ€§å¼·åŒ–è¨“ç·´...")
    results = model.train(
        data=DATA_YAML,
        epochs=300,
        imgsz=640,
        batch=8,
        patience=50,
        workers=4,
        
        # --- æ¬Šé‡èˆ‡å¹³æ»‘ (é˜²èª¤åˆ¤) ---
        cls=2.0,           # æé«˜é¡åˆ¥æ¬Šé‡ï¼Œè®“æ¨¡å‹æ›´åœ¨æ„ã€ŒèªéŒ¯äººã€
        label_smoothing=0.1, 

        # --- æ•¸æ“šå¢å¼· (å°æ¨£æœ¬ç‰¹æ•ˆè—¥) ---
        degrees=20.0,      # æ—‹è½‰
        shear=10.0,        # é€è¦–è®Šå½¢ (è§£æ±ºåœ‹è¾²ä¸Šæ‹å•é¡Œ)
        perspective=0.001,
        mosaic=1.0,        # å¿…é–‹
        mixup=0.2,         # è§£æ±ºéº¥é¦™/å’–å•¡å»£å ´é¡è‰²ç›¸ä¼¼
        copy_paste=0.4,    # æœ€å¼·æ‹›ï¼šéš¨æ©Ÿå°‡å•†å“è²¼åˆ°ä¸åŒèƒŒæ™¯
        
        optimizer='SGD',   # æ¨£æœ¬å°‘æ™‚ SGD è¼ƒç©©å®š
        device=0,
        project='03_AI_Lab/runs/train',
        name='grocery_v4_stable_final',
    )

    # 4. é©—è­‰èˆ‡åŒ¯å‡º
    model.val()
    print("ğŸ“¦ å°å‡ºæ‰‹æ©Ÿç«¯å°ˆç”¨ ONNX (FP16)...")
    model.export(format='onnx', opset=13, half=True, simplify=True)

if __name__ == '__main__':
    train_grocery_model()