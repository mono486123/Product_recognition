import os
import cv2
from ultralytics import YOLO

def augment_dataset_by_flipping(data_root):
    """
    æƒæè¨“ç·´é›†ï¼Œè‡ªå‹•ç”Ÿæˆæ°´å¹³ç¿»è½‰çš„åœ–ç‰‡èˆ‡æ¨™ç±¤ (YOLO æ ¼å¼)
    """
    train_img_dir = os.path.join(data_root, "train", "images")
    train_lab_dir = os.path.join(data_root, "train", "labels")
    
    if not os.path.exists(train_img_dir):
        print(f"âš ï¸ æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™å¤¾ï¼Œè·³éç¿»è½‰æ­¥é©Ÿï¼š{train_img_dir}")
        return

    print("ğŸ”„ æ­£åœ¨å•Ÿå‹•è³‡æ–™ç¿»è½‰æ“´å…… (Offline Augmentation)...")
    img_list = [f for f in os.listdir(train_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    count = 0
    for img_name in img_list:
        # é¿å…é‡è¤‡ç¿»è½‰å·²ç¶“ç¿»è½‰éçš„æª”æ¡ˆ
        if "_flip" in img_name:
            continue
            
        base_name = os.path.splitext(img_name)[0]
        img_path = os.path.join(train_img_dir, img_name)
        lab_path = os.path.join(train_lab_dir, base_name + ".txt")
        
        # 1. ç¿»è½‰åœ–ç‰‡ä¸¦å„²å­˜
        output_img_path = os.path.join(train_img_dir, f"{base_name}_flip.jpg")
        if not os.path.exists(output_img_path):
            img = cv2.imread(img_path)
            if img is None: continue
            flipped_img = cv2.flip(img, 1) # 1 ä»£è¡¨æ°´å¹³ç¿»è½‰
            cv2.imwrite(output_img_path, flipped_img)

        # 2. ç¿»è½‰æ¨™ç±¤ä¸¦å„²å­˜
        if os.path.exists(lab_path):
            output_lab_path = os.path.join(train_lab_dir, f"{base_name}_flip.txt")
            if not os.path.exists(output_lab_path):
                with open(lab_path, 'r') as f:
                    lines = f.readlines()
                
                new_labels = []
                for line in lines:
                    parts = line.split()
                    if len(parts) == 5:
                        cls, x, y, w, h = map(float, parts)
                        # æ°´å¹³ç¿»è½‰æ ¸å¿ƒé‚è¼¯ï¼šæ–°çš„ x åº§æ¨™ = 1.0 - åŸæœ¬çš„ x åº§æ¨™
                        new_x = 1.0 - x
                        new_labels.append(f"{int(cls)} {new_x:.6f} {y:.6f} {w:.6f} {h:.6f}")
                
                with open(output_lab_path, 'w') as f:
                    f.write("\n".join(new_labels))
                count += 1
                    
    print(f"âœ… è³‡æ–™ç¿»è½‰æ“´å……å®Œæˆï¼å…±æ–°å¢äº† {count} çµ„åœ–ç‰‡èˆ‡æ¨™ç±¤ã€‚")

def finetune_grocery_model():
    # --- 1. è·¯å¾‘è¨­å®š ---
    # è³‡æ–™é›†æ ¹ç›®éŒ„ (åŒ…å« train/val è³‡æ–™å¤¾çš„åœ°æ–¹)
    DATA_ROOT = r"D:\product_recognition\03_AI_Lab\yolo11_data"
    DATA_YAML_PATH = os.path.join(DATA_ROOT, "data.yaml")
    
    # ä¹‹å‰è¡¨ç¾æœ€å¥½çš„æ¬Šé‡
    PREVIOUS_BEST_MODEL = r"D:\product_recognition\03_AI_Lab\runs\train\grocery_recognition_v2_Augmented_fake_background\weights\best.pt"
    
    # æ–°è¨“ç·´ä»»å‹™åç¨±
    PROJECT_NAME = 'grocery_recognition_v2_Finetuned_with_Flip'
    
    # --- 2. åŸ·è¡Œç·šä¸‹æ“´å…… ---
    # é€™æ­¥æœƒæ”¹å‹•ç¡¬ç¢Ÿç©ºé–“ï¼Œåªéœ€åŸ·è¡Œä¸€æ¬¡ï¼ˆè…³æœ¬å…§å·²åŒ…å«éæ¿¾é‚è¼¯ï¼‰
    augment_dataset_by_flipping(DATA_ROOT)

    # --- 3. è¼‰å…¥æ¨¡å‹èˆ‡å¾®èª¿è¨“ç·´ ---
    if not os.path.exists(PREVIOUS_BEST_MODEL):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åŸºç¤æ¬Šé‡æª”æ¡ˆ {PREVIOUS_BEST_MODEL}")
        return

    print(f"ğŸ”„ è¼‰å…¥ {PREVIOUS_BEST_MODEL} é€²è¡Œå¾®èª¿...")
    model = YOLO(PREVIOUS_BEST_MODEL)

    model.train(
        data=DATA_YAML_PATH,
        epochs=250,
        imgsz=640,
        batch=16,
        project='03_AI_Lab/runs/train',
        name=PROJECT_NAME,
        exist_ok=True,
        device=0,
        lr0=0.001,      # å¾®èª¿ä½¿ç”¨è¼ƒå°å­¸ç¿’ç‡
        patience=10,    # 10ä»£æ²’é€²æ­¥è‡ªå‹•åœæ­¢
        workers=2,
        augment=True    # é–‹å•Ÿ YOLO å…§å»ºçš„ç·šä¸Šå¢å¼·
    )

    # --- 4. é©—è­‰èˆ‡å°å‡º ---
    print("ğŸ“Š åŸ·è¡Œæœ€å¾Œé©—è­‰...")
    model.val()

    print("ğŸ“¦ æ­£åœ¨å°å‡ºæ‰‹æ©Ÿç«¯å°ˆç”¨ ONNX...")
    onnx_path = model.export(format='onnx', opset=13)
    print(f"ğŸš€ å°å‡ºæˆåŠŸï¼æª”æ¡ˆä½æ–¼ï¼š{onnx_path}")

if __name__ == '__main__':
    finetune_grocery_model()